{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPk+27qiOBZ7i5NDzRv0vQf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denisangelo/Federated_Learning/blob/main/DP3_FL_Yes_Division_Dataset_Cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PViYpk4rY9qS",
        "outputId": "df59dce6-9a2e-4c91-98c9-02a7e11fec25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opacus in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from opacus) (2.0.1+cu118)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.10/dist-packages (from opacus) (1.10.1)\n",
            "Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from opacus) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->opacus) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->opacus) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->opacus) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->opacus) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->opacus) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "#Importanto Pytorch, Flower,Opacus\n",
        "!pip install -q flwr[simulation]\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install matplotlib\n",
        "!pip install opacus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importanto as bibliotecas necess√°rias\n",
        "from collections import OrderedDict\n",
        "from typing import Dict, Optional, List, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import flwr as fl\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from flwr.common import Metrics\n",
        "import torchvision.transforms as transforms\n",
        "import opacus\n",
        "from opacus import PrivacyEngine\n",
        "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
        "from torch.optim.adam import Adam\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import CIFAR10"
      ],
      "metadata": {
        "id": "A7BPOyZdZFNl"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Definindo o dispositivo de treinamento\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on {DEVICE} using Pytorch{torch.__version__}, Flower{fl.__version__} and Opacus{opacus.__version__ }\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-jlFGuNZJkF",
        "outputId": "2df2d3a3-f69b-41d0-d2cd-67ae03237aa6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu using Pytorch2.0.1+cu118, Flower1.4.0 and Opacus1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo os valores das vari√°veis\n",
        "BATCH_SIZE = 100\n",
        "NUM_CLIENTS= 10\n",
        "optim_lr=0.001\n",
        "local_epochs=5\n",
        "num_rounds=10\n",
        "noise_multiplier=1.1\n",
        "max_grad_norm=1.2"
      ],
      "metadata": {
        "id": "OPCD_dDmZQQM"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Carregando os dados\n",
        "def load_data():\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize( (0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    trainset = CIFAR10(root=\"./data\", train=True,download=True, transform=transform)\n",
        "    testset = CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "    partition_size = len(trainset) // NUM_CLIENTS\n",
        "    lengths = [partition_size] * NUM_CLIENTS\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10 # 10% do conjunto para testes\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths =[len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True,num_workers=0))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE, shuffle=False,num_workers=0))\n",
        "        testloader = DataLoader(testset,batch_size=BATCH_SIZE, shuffle=False,num_workers=0)\n",
        "        num_examples = {\"ds_train\": len(ds_train)*BATCH_SIZE, \"ds_val\": len(ds_val)*BATCH_SIZE}\n",
        "\n",
        "    return trainloaders, valloaders, testloader,num_examples\n",
        "    \n",
        "trainloaders, valloaders, testloader,num_examples = load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7gh4YemZZk8",
        "outputId": "7295c07e-ce4a-4bb5-ceba-9b1c02f0b57b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo o Modelo\n",
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "BKIIit4XZe6V"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Definindo as fun√ß√µes de treino e teste\n",
        "def train(net, trainloader,optimizer,privacy_engine, epochs):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for _ in range(epochs):\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "def test(net, testloader):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "VCMZt-97ZlJM"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√µes de atualiza√ß√£o de par√¢metros do modelo\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)"
      ],
      "metadata": {
        "id": "OrxCgmgeZpI0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo a classe de cliente Virtual\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader, num_example,optimizer,privacy_engine)-> None:\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.num_example = num_example\n",
        "        self.optimizer = optimizer\n",
        "        self.privacy_engine = privacy_engine\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader,self.optimizer,self.privacy_engine,epochs=local_epochs)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "        net = Net().to(DEVICE)\n",
        "        trainloader = trainloaders[int(cid)]\n",
        "        valloader = valloaders[int(cid)]\n",
        "        num_example = num_examples\n",
        "        optimizer = torch.optim.Adam(net.parameters(),lr=optim_lr)\n",
        "        privacy_engine = PrivacyEngine()\n",
        "        net, optimizer, trainloader = privacy_engine.make_private(\n",
        "        module=net,\n",
        "        optimizer=optimizer,\n",
        "        data_loader=trainloader,\n",
        "        noise_multiplier=noise_multiplier,\n",
        "        max_grad_norm=max_grad_norm, )\n",
        "        return FlowerClient(cid, net, trainloader, valloader, num_example,optimizer,privacy_engine)"
      ],
      "metadata": {
        "id": "eK_KdJy3Zthc"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizando a agrega√ß√£o\n",
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "metadata": {
        "id": "EjL_jT2tZwtj"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iniciando o treino federado\n",
        "# Criando a Fun√ß√£o de agrega√ß√£o FedAvg\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,#-->Fra√ß√£o de clientes necess√°rios para treinamento\n",
        "    fraction_evaluate=1.0, #--> Fra√ß√£o de clientes que ser√£o utilizados para teste\n",
        "    min_fit_clients=NUM_CLIENTS, #--> N√∫mero m√≠nimo que ser√£o utlilizados para treinamento\n",
        "    min_evaluate_clients=2, #--> N√∫mero m√≠nimo de clientes que ser√£o realizados para teste\n",
        "    min_available_clients=NUM_CLIENTS,#--> N√∫mero m√≠nimo de clientes que ser√£o utilizados no treinamento\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,  \n",
        ")\n",
        "client_resources = None\n",
        "if DEVICE.type == \"cuda\":\n",
        "    client_resources = {\"num_gpus\": 1}\n",
        "# Inicia a simula√ß√£o\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=num_rounds),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fRBxvdyZ02t",
        "outputId": "2f423dd9-4722-4485-9268-03226cefd4bc"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-06-11 13:12:41,152 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3528)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-06-11 13:12:49,452\tINFO worker.py:1636 -- Started a local Ray instance.\n",
            "INFO flwr 2023-06-11 13:12:51,995 | app.py:180 | Flower VCE: Ray initialized with resources: {'memory': 7832140187.0, 'object_store_memory': 3916070092.0, 'node:172.28.0.12': 1.0, 'CPU': 2.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'memory': 7832140187.0, 'object_store_memory': 3916070092.0, 'node:172.28.0.12': 1.0, 'CPU': 2.0}\n",
            "INFO flwr 2023-06-11 13:12:51,999 | server.py:86 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-06-11 13:12:52,002 | server.py:273 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=6175)\u001b[0m 2023-06-11 13:12:59.983352: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO flwr 2023-06-11 13:13:05,217 | server.py:277 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2023-06-11 13:13:05,221 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-06-11 13:13:05,223 | server.py:101 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-06-11 13:13:05,225 | server.py:218 | fit_round 1: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_get_parameters pid=6175)\u001b[0m [Client 2] get_parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_get_parameters pid=6175)\u001b[0m /usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "\u001b[2m\u001b[36m(launch_and_get_parameters pid=6175)\u001b[0m   warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 9] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m   warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
            "\u001b[2m\u001b[36m(pid=6176)\u001b[0m 2023-06-11 13:13:20.359548: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 3] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m /usr/local/lib/python3.10/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m   warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 8] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 6] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:17:08,741 | server.py:232 | fit_round 1 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 10 results and 0 failures\n",
            "WARNING flwr 2023-06-11 13:17:08,780 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-06-11 13:17:08,792 | server.py:168 | evaluate_round 1: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m [Client 9] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m [Client 4] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6175)\u001b[0m [Client 5] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6175)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:17:28,183 | server.py:182 | evaluate_round 1 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-06-11 13:17:28,186 | server.py:218 | fit_round 2: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6175)\u001b[0m [Client 8] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 5] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 0] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:21:16,790 | server.py:232 | fit_round 2 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-06-11 13:21:16,838 | server.py:168 | evaluate_round 2: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6175)\u001b[0m [Client 2] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m [Client 5] evaluate, config: {}\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:21:39,508 | server.py:182 | evaluate_round 2 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-06-11 13:21:39,513 | server.py:218 | fit_round 3: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6175)\u001b[0m [Client 7] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 5] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:25:18,330 | server.py:232 | fit_round 3 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-06-11 13:25:18,371 | server.py:168 | evaluate_round 3: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:25:39,523 | server.py:182 | evaluate_round 3 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-06-11 13:25:39,528 | server.py:218 | fit_round 4: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m [Client 5] evaluate, config: {}\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 8] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 9] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:29:16,576 | server.py:232 | fit_round 4 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-06-11 13:29:16,608 | server.py:168 | evaluate_round 4: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6175)\u001b[0m [Client 9] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6175)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m \n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:29:39,173 | server.py:182 | evaluate_round 4 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-06-11 13:29:39,179 | server.py:218 | fit_round 5: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m [Client 7] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 4] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 7] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:33:24,870 | server.py:232 | fit_round 5 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-06-11 13:33:24,906 | server.py:168 | evaluate_round 5: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m [Client 6] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 6] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:33:47,980 | server.py:182 | evaluate_round 5 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-06-11 13:33:47,984 | server.py:218 | fit_round 6: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 6: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 7] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:37:22,195 | server.py:232 | fit_round 6 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 6 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-06-11 13:37:22,231 | server.py:168 | evaluate_round 6: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 6: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6175)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 8] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:37:41,751 | server.py:182 | evaluate_round 6 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 6 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-06-11 13:37:41,754 | server.py:218 | fit_round 7: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 7: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 6] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6175)\u001b[0m [Client 7] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 5] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 9] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 8] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:41:25,759 | server.py:232 | fit_round 7 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 7 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-06-11 13:41:25,798 | server.py:168 | evaluate_round 7: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 7: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m [Client 9] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6175)\u001b[0m [Client 5] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6175)\u001b[0m \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:41:45,488 | server.py:182 | evaluate_round 7 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 7 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-06-11 13:41:45,496 | server.py:218 | fit_round 8: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 8: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6175)\u001b[0m [Client 7] evaluate, config: {}\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 8] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 7] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 2] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 0] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:45:31,736 | server.py:232 | fit_round 8 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 8 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-06-11 13:45:31,769 | server.py:168 | evaluate_round 8: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 8: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m [Client 3] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6175)\u001b[0m [Client 1] evaluate, config: {}\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:45:51,847 | server.py:182 | evaluate_round 8 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 8 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-06-11 13:45:51,853 | server.py:218 | fit_round 9: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 9: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6175)\u001b[0m [Client 6] evaluate, config: {}\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 6] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 7] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:49:31,303 | server.py:232 | fit_round 9 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 9 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-06-11 13:49:31,348 | server.py:168 | evaluate_round 9: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 9: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m [Client 4] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 4] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6175)\u001b[0m [Client 8] evaluate, config: {}\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:49:50,740 | server.py:182 | evaluate_round 9 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 9 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-06-11 13:49:50,743 | server.py:218 | fit_round 10: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 10: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 5] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m [Client 6] evaluate, config: {}\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 8] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6175)\u001b[0m [Client 9] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:53:42,848 | server.py:232 | fit_round 10 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 10 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-06-11 13:53:42,880 | server.py:168 | evaluate_round 10: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 10: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=6176)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=6176)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-11 13:54:06,327 | server.py:182 | evaluate_round 10 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 10 received 10 results and 0 failures\n",
            "INFO flwr 2023-06-11 13:54:06,335 | server.py:147 | FL finished in 2461.109609581\n",
            "INFO:flwr:FL finished in 2461.109609581\n",
            "INFO flwr 2023-06-11 13:54:06,338 | app.py:218 | app_fit: losses_distributed [(1, 0.02184689321517944), (2, 0.02018462200164795), (3, 0.019562390422821044), (4, 0.019296553707122802), (5, 0.019132028031349183), (6, 0.01903420445919037), (7, 0.018847941040992737), (8, 0.01875178439617157), (9, 0.018615554451942445), (10, 0.018551428031921384)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.02184689321517944), (2, 0.02018462200164795), (3, 0.019562390422821044), (4, 0.019296553707122802), (5, 0.019132028031349183), (6, 0.01903420445919037), (7, 0.018847941040992737), (8, 0.01875178439617157), (9, 0.018615554451942445), (10, 0.018551428031921384)]\n",
            "INFO flwr 2023-06-11 13:54:06,340 | app.py:219 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-06-11 13:54:06,343 | app.py:220 | app_fit: metrics_distributed {'accuracy': [(1, 0.2278), (2, 0.27699999999999997), (3, 0.3016), (4, 0.3114), (5, 0.32160000000000005), (6, 0.32900000000000007), (7, 0.3324000000000001), (8, 0.3406), (9, 0.35), (10, 0.3538)]}\n",
            "INFO:flwr:app_fit: metrics_distributed {'accuracy': [(1, 0.2278), (2, 0.27699999999999997), (3, 0.3016), (4, 0.3114), (5, 0.32160000000000005), (6, 0.32900000000000007), (7, 0.3324000000000001), (8, 0.3406), (9, 0.35), (10, 0.3538)]}\n",
            "INFO flwr 2023-06-11 13:54:06,345 | app.py:221 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2023-06-11 13:54:06,347 | app.py:222 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.02184689321517944\n",
              "\tround 2: 0.02018462200164795\n",
              "\tround 3: 0.019562390422821044\n",
              "\tround 4: 0.019296553707122802\n",
              "\tround 5: 0.019132028031349183\n",
              "\tround 6: 0.01903420445919037\n",
              "\tround 7: 0.018847941040992737\n",
              "\tround 8: 0.01875178439617157\n",
              "\tround 9: 0.018615554451942445\n",
              "\tround 10: 0.018551428031921384\n",
              "History (metrics, distributed, evaluate):\n",
              "{'accuracy': [(1, 0.2278), (2, 0.27699999999999997), (3, 0.3016), (4, 0.3114), (5, 0.32160000000000005), (6, 0.32900000000000007), (7, 0.3324000000000001), (8, 0.3406), (9, 0.35), (10, 0.3538)]}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}