{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsbX6aphpsAuDicBPz6jvW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/denisangelo/Federated_Learning/blob/main/Federated_Learning%20/Notebooks/Aula_2_Treinamento_Federado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "-9DThh0hncch"
      },
      "outputs": [],
      "source": [
        "# Instalando a plataforma/bibliotecas e suas dependências\n",
        "!pip install -q flwr[simulation] torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "import flwr as fl\n",
        "from flwr.common import Metrics\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(\n",
        "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3RY7vWdnhu_",
        "outputId": "8b0e2f96-5eef-4af9-c8d5-5da83f9894ca"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu using PyTorch 2.0.1+cu118 and Flower 1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define o número de clientes a serem realizados no treinamento:\n",
        "NUM_CLIENTS =5\n",
        "CLASSES =('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') \n",
        "BATCH_SIZE= 64"
      ],
      "metadata": {
        "id": "I-0gplPWnmPN"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # Carregando e Normalizando os Dados CIFAR10\n",
        "  # Definindo as Transformações a serem aplicadas às imagens\n",
        "def load_data():\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "    trainset = CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "    testset = CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "    partition_size = len(trainset) // NUM_CLIENTS\n",
        "    lengths = [partition_size] * NUM_CLIENTS\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10 # 10% do conjunto para testes\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths =[len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True,num_workers=2))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE, shuffle=False,num_workers=2))\n",
        "        testloader = DataLoader(testset,batch_size=BATCH_SIZE, shuffle=False,num_workers=2)\n",
        "    return trainloaders, valloaders, testloader\n",
        "    \n",
        "trainloaders, valloaders, testloader = load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftU5hYnZno_e",
        "outputId": "e0a3feda-258e-4848-f970-b8d3095513e4"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo o Modelo\n",
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "I646Y4tjpCim"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo as funções de treinamento\n",
        "def train(net, trainloader, epochs: int, verbose=False):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ],
      "metadata": {
        "id": "gMrhS8lNo1Eq"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funções de atualização de parâmetros do modelo\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)"
      ],
      "metadata": {
        "id": "64DjrXDFvKz_"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definindo a classe de cliente Virtual\n",
        "class FlowerNumPyClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "def numpyclient_fn(cid) -> FlowerNumPyClient:\n",
        "        net = Net().to(DEVICE)\n",
        "        trainloader = trainloaders[int(cid)]\n",
        "        valloader = valloaders[int(cid)]\n",
        "        return FlowerNumPyClient(cid, net, trainloader, valloader)"
      ],
      "metadata": {
        "id": "TOOPzieItXno"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizando a agregação\n",
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ],
      "metadata": {
        "id": "wEUKgivtrW3A"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iniciando o treino federado\n",
        "# Criando a Função de agregação FedAvg\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,#-->Fração de clientes necessários para treinamento\n",
        "    fraction_evaluate=0.5, #--> Fração de clientes que serão utilizados para teste\n",
        "    min_fit_clients=NUM_CLIENTS, #--> Número mínimo que serão utlilizados para treinamento\n",
        "    min_evaluate_clients=2, #--> Número mínimo de clientes que serão realizados para teste\n",
        "    min_available_clients=NUM_CLIENTS,#--> Número mínimo de clientes que serão utilizados no treinamento\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,  \n",
        ")\n",
        "client_resources = None\n",
        "if DEVICE.type == \"cuda\":\n",
        "    client_resources = {\"num_gpus\": 1}\n",
        "# Inicia a simulação\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=numpyclient_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0jPnzswqFFe",
        "outputId": "55eb15d2-0b86-4dc7-de06-155821dc9c87"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-06-02 15:00:10,119 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "2023-06-02 15:00:15,150\tINFO worker.py:1625 -- Started a local Ray instance.\n",
            "INFO flwr 2023-06-02 15:00:17,119 | app.py:180 | Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'memory': 7774362011.0, 'object_store_memory': 3887181004.0, 'node:172.28.0.12': 1.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'memory': 7774362011.0, 'object_store_memory': 3887181004.0, 'node:172.28.0.12': 1.0}\n",
            "INFO flwr 2023-06-02 15:00:17,125 | server.py:86 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-06-02 15:00:17,129 | server.py:273 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=5525)\u001b[0m 2023-06-02 15:00:26.667522: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO flwr 2023-06-02 15:00:31,341 | server.py:277 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2023-06-02 15:00:31,346 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-06-02 15:00:31,352 | server.py:101 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-06-02 15:00:31,356 | server.py:218 | fit_round 1: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_get_parameters pid=5525)\u001b[0m [Client 2] get_parameters\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5525)\u001b[0m [Client 2] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=5526)\u001b[0m 2023-06-02 15:00:45.164161: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=5525)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5526)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5526)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-02 15:01:13,077 | server.py:232 | fit_round 1 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 5 results and 0 failures\n",
            "WARNING flwr 2023-06-02 15:01:13,104 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-06-02 15:01:13,108 | server.py:168 | evaluate_round 1: strategy sampled 2 clients (out of 5)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 2 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5525)\u001b[0m [Client 3] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-02 15:01:18,622 | server.py:182 | evaluate_round 1 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 2 results and 0 failures\n",
            "DEBUG flwr 2023-06-02 15:01:18,627 | server.py:218 | fit_round 2: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=5525)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5526)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5526)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5526)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-02 15:01:57,928 | server.py:232 | fit_round 2 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-06-02 15:01:57,950 | server.py:168 | evaluate_round 2: strategy sampled 2 clients (out of 5)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 2 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5526)\u001b[0m [Client 3] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-02 15:02:02,055 | server.py:182 | evaluate_round 2 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 2 results and 0 failures\n",
            "DEBUG flwr 2023-06-02 15:02:02,060 | server.py:218 | fit_round 3: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=5525)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5525)\u001b[0m [Client 3] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5525)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5525)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-02 15:02:39,394 | server.py:232 | fit_round 3 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-06-02 15:02:39,414 | server.py:168 | evaluate_round 3: strategy sampled 2 clients (out of 5)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 2 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5525)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-02 15:02:43,665 | server.py:182 | evaluate_round 3 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 2 results and 0 failures\n",
            "DEBUG flwr 2023-06-02 15:02:43,669 | server.py:218 | fit_round 4: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=5525)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5526)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5526)\u001b[0m [Client 4] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5525)\u001b[0m [Client 3] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-02 15:03:23,353 | server.py:232 | fit_round 4 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-06-02 15:03:23,387 | server.py:168 | evaluate_round 4: strategy sampled 2 clients (out of 5)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 2 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5525)\u001b[0m [Client 3] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-02 15:03:28,348 | server.py:182 | evaluate_round 4 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 2 results and 0 failures\n",
            "DEBUG flwr 2023-06-02 15:03:28,354 | server.py:218 | fit_round 5: strategy sampled 5 clients (out of 5)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 5 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=5526)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5526)\u001b[0m [Client 2] fit, config: {}\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5526)\u001b[0m [Client 0] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=5526)\u001b[0m [Client 1] fit, config: {}\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-02 15:04:06,288 | server.py:232 | fit_round 5 received 5 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 5 results and 0 failures\n",
            "DEBUG flwr 2023-06-02 15:04:06,314 | server.py:168 | evaluate_round 5: strategy sampled 2 clients (out of 5)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 2 clients (out of 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=5525)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-06-02 15:04:10,712 | server.py:182 | evaluate_round 5 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 2 results and 0 failures\n",
            "INFO flwr 2023-06-02 15:04:10,718 | server.py:147 | FL finished in 219.3627942469999\n",
            "INFO:flwr:FL finished in 219.3627942469999\n",
            "INFO flwr 2023-06-02 15:04:10,724 | app.py:218 | app_fit: losses_distributed [(1, 0.03073211431503296), (2, 0.026730689287185666), (3, 0.024968858659267425), (4, 0.024011496186256406), (5, 0.023463268995285034)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.03073211431503296), (2, 0.026730689287185666), (3, 0.024968858659267425), (4, 0.024011496186256406), (5, 0.023463268995285034)]\n",
            "INFO flwr 2023-06-02 15:04:10,727 | app.py:219 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-06-02 15:04:10,732 | app.py:220 | app_fit: metrics_distributed {'accuracy': [(1, 0.3035), (2, 0.39249999999999996), (3, 0.429), (4, 0.4585), (5, 0.479)]}\n",
            "INFO:flwr:app_fit: metrics_distributed {'accuracy': [(1, 0.3035), (2, 0.39249999999999996), (3, 0.429), (4, 0.4585), (5, 0.479)]}\n",
            "INFO flwr 2023-06-02 15:04:10,737 | app.py:221 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2023-06-02 15:04:10,739 | app.py:222 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.03073211431503296\n",
              "\tround 2: 0.026730689287185666\n",
              "\tround 3: 0.024968858659267425\n",
              "\tround 4: 0.024011496186256406\n",
              "\tround 5: 0.023463268995285034\n",
              "History (metrics, distributed, evaluate):\n",
              "{'accuracy': [(1, 0.3035), (2, 0.39249999999999996), (3, 0.429), (4, 0.4585), (5, 0.479)]}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    }
  ]
}